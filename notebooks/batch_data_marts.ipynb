{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd1871d-347e-478b-9705-efbeba0d1258",
   "metadata": {},
   "source": [
    "# Init spark session with aerospike connector "
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "e3aadacd-3264-45a9-ae66-9fb82d4fe4a3",
   "metadata": {},
   "source": [
    "#### without aerospike"
   ]
  },
  {
=======
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bccb784-67df-4e26-ae7a-9c6891d5c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.driver.cores', 10) \\\n",
    "    .config('spark.driver.memory', '36g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "7fc75026-a35d-44a0-8313-cca90b203140",
   "metadata": {},
   "source": [
    "#### with aerospike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
=======
   "cell_type": "code",
   "execution_count": 6,
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
   "id": "dbb1d59e-69ff-4a9c-8695-895ab04a37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "# IP Address or DNS name for one host in your Aerospike cluster\n",
    "AS_HOST = \"aerospikedb_1\"\n",
    "# Name of one of your namespaces. Type 'show namespaces' at the aql prompt if you are not sure\n",
    "AS_NAMESPACE = \"test\" \n",
    "AEROSPIKE_SPARK_JAR_VERSION=\"3.2.0\"\n",
    "AS_PORT = 3000 # Usually 3000, but change here if not\n",
    "AS_CONNECTION_STRING = AS_HOST + \":\"+ str(AS_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4d93a3-7ba9-4e13-a2a8-7acddb1ba5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "AEROSPIKE_JAR_PATH= \"../src/drivers/aerospike-spark-assembly-\"+AEROSPIKE_SPARK_JAR_VERSION+\".jar\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--jars ' + AEROSPIKE_JAR_PATH + ' pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b4174c-7ae4-456b-b614-c9bbfae53af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
<<<<<<< HEAD
      "21/11/28 09:47:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/28 09:47:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/11/28 09:47:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
=======
      "21/11/27 21:21:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/27 21:21:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/11/27 21:21:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "conf = sc \\\n",
    "    ._conf \\\n",
    "    .setAll([\n",
    "    (\"aerospike.namespace\", AS_NAMESPACE),\n",
    "    (\"aerospike.seedhost\", AS_CONNECTION_STRING), \n",
    "    (\"aerospike.log.level\", \"info\"),\n",
    "    (\"spark.driver.cores\", 10),\n",
    "    (\"spark.driver.memory\", '36g')\n",
    "])\n",
    "sc.stop()\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a59e82e-6aee-49a2-ae01-c9f1367130df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### read raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a994f136-123f-454e-ae88-3664cf45d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make time_key a valid datetime col\n",
    "df_agg_usage = spark.read \\\n",
    "    .format('parquet') \\\n",
    "    .load('../data/agg_usage.parquet') \\\n",
    "    .withColumn('time_key', f.to_date(f.split(f.col('time_key'), 'P').getItem(1), \n",
    "                                      format='yyyy-MM-dd'))\n",
    "\n",
    "df_agg_usage.registerTempTable('agg_usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6856f6f-342c-4747-8964-80b869785853",
   "metadata": {},
   "source": [
    "### prepare data traffic mart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cc882c4-03cf-40dc-afe9-c880c728eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_group = [f.col('client_id'), f.col('time_key')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f1f49a6-c086-49e9-a849-ebde004bd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only necessary cols & round data_volume to Mb\n",
    "df_base = df_agg_usage.select(\n",
    "    f.col('client_id'),\n",
    "    f.col('time_key'),\n",
    "    f.col('call_type_key'),\n",
    "    f.col('roaming_type_key'),\n",
    "    f.col('network_type'),\n",
    "    (f.col('rounded_data_volume') / (1024^2)).alias('data_rdv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b221ca87-4bdb-4ba0-9b3e-785090dcd024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_traffic = df_base \\\n",
    "    .filter(f.col('call_type_key').isin(['G', 'Y', 'X'])) \\\n",
    "    .filter(f.col('roaming_type_key').isin(['X', 'R', 'H']))\n",
    "\n",
    "df_data_traffic_4g = df_data_traffic \\\n",
    "    .filter(f.col('network_type') == 'L') \\\n",
    "    .groupby(to_group) \\\n",
    "    .agg(f.sum(f.col('data_rdv')).alias('data_4g_mb'))\n",
    "\n",
    "df_data_traffic_3g = df_data_traffic \\\n",
    "    .filter(f.col('network_type') == 'G') \\\n",
    "    .groupby(to_group) \\\n",
    "    .agg(f.sum(f.col('data_rdv')).alias('data_3g_mb'))\n",
    "\n",
    "df_data_traffic = df_data_traffic \\\n",
    "    .groupby(to_group) \\\n",
    "    .agg(f.sum(f.col('data_rdv')).alias('data_all_mb'))\n",
    "\n",
    "df_data_traffic = df_data_traffic.join(df_data_traffic_4g, on=['client_id', 'time_key'], how='left')\n",
    "df_data_traffic = df_data_traffic.join(df_data_traffic_3g, on=['client_id', 'time_key'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0d29793-58d2-44e2-90e5-34c48cb38cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save locally as orc\n",
    "df_data_traffic.write \\\n",
    "    .format('orc') \\\n",
    "    .mode('overwrite') \\\n",
    "    .save('/home/jovyan/work/data/data_traffic_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14956c18-8ae9-484d-ba68-113d7f12ccc4",
   "metadata": {},
   "source": [
    "### prepare voice traffic mart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0719a63e-603f-4a72-9b9a-ed90dccdb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_operator is a small table, we can do broadcast join to increase performance\n",
    "df_parent_operator = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .option('header', True) \\\n",
    "    .load('../data/parent_operator.csv') \\\n",
    "    .withColumnRenamed('parent_operator_code', 'parent_operator_code_b')\n",
    "\n",
    "df_agg_usage = df_agg_usage.join(\n",
    "    f.broadcast(df_parent_operator),\n",
    "    on='parent_operator_code_b',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6da5e994-1031-4f3f-867f-0445f17d76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern of aggregation is the same for all columns\n",
    "# so we can parse the column name in order to make a pipeline of transformations\n",
    "def get_aggregation(filters, agg):\n",
    "    df_agg = df_agg_usage\n",
    "    \n",
    "    for condition in filters:\n",
    "        df_agg = df_agg.filter(condition)\n",
    "        \n",
    "    df_agg = df_agg \\\n",
    "        .groupby(to_group) \\\n",
    "        .agg(agg)\n",
    "    \n",
    "    return df_agg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b3c3a58-262f-445e-b5e5-6cf864bf717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filters and aggregation columns according to the .pptx manual\n",
    "filters = {\n",
    "    'in': [f.col('call_direction_ind') == 1],\n",
    "    'out': [f.col('call_direction_ind') == 2],\n",
    "    'onnet': [f.col('call_type_key') == 'V', f.col('group_operator_code') == 'BLN'],\n",
    "    'intercity': [f.col('location_type_key') == 1],\n",
    "    'international': [f.col('location_type_key') == 3],\n",
    "    'nopackage': [f.col('charge_amt_rur') > 0]\n",
    "}\n",
    "\n",
    "agg = {\n",
    "    'cnt': f.sum(f.col('num_of_call')),\n",
    "    'sec': f.sum(f.col('actual_call_dur_sec'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "256454c9-65a5-4d16-8e4c-f9359af99155",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'voice_in_cnt',\n",
<<<<<<< HEAD
    "    'voice_in_sec',\n",
=======
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
    "    'voice_international_in_sec',\n",
    "    'voice_international_in_cnt',\n",
    "    'voice_international_out_sec',\n",
    "    'voice_international_out_cnt',\n",
    "    'voice_intercity_in_cnt',\n",
    "    'voice_intercity_out_sec',\n",
    "    'voice_intercity_in_sec',\n",
    "    'voice_intercity_out_cnt',\n",
    "    'voice_out_sec',\n",
    "    'voice_out_nopackage_sec',\n",
    "    'voice_out_cnt',\n",
    "    'voice_onnet_in_cnt',\n",
    "    'voice_onnet_out_cnt',\n",
    "    'voice_onnet_out_sec',\n",
    "    'voice_onnet_in_sec',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5561a574-fd4d-40c1-ac9a-b3b0b8e53dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all columns\n",
    "aggregations = []\n",
    "\n",
    "for col in cols:\n",
    "    pipeline = col.split('voice_')[1]\n",
    "    filters_for_df = [condition for fil in pipeline.split('_')[:-1] for condition in filters[fil]]\n",
    "    agg_for_df = agg[pipeline.split('_')[-1]].alias(col)\n",
    "    \n",
    "    df = get_aggregation(filters_for_df, agg_for_df)\n",
    "    \n",
    "    aggregations.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "234b1cb8-de8b-4706-8cf7-59f161e878e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voice_traffic = df_agg_usage.select(f.col('client_id'),\n",
    "                              f.col('time_key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87c7abbb-aeed-4700-b9e8-436d7b27c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_agg in aggregations:\n",
    "    df_voice_traffic = df_voice_traffic.join(df_agg, on=['client_id', 'time_key'], how='left')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": null,
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
   "id": "ad1b99d7-072c-49f1-9683-e319e098eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "                                                                                \r"
=======
      "[Stage 50:> (4 + 10) / 15][Stage 51:>  (0 + 0) / 15][Stage 52:>  (0 + 0) / 15]\r"
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
     ]
    }
   ],
   "source": [
    "# save the data mart locally\n",
    "df_voice_traffic.write \\\n",
    "    .format('orc') \\\n",
    "    .mode('overwrite') \\\n",
    "    .save('/home/jovyan/work/data/voice_traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ccf93-9764-4256-ae8a-387b0d348645",
   "metadata": {},
   "source": [
    "### calculate client_profile mart & load to aerospike"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
   "id": "52117e16-6d42-465d-8fe4-7b5c8b2a4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_traffic = spark \\\n",
    "    .read \\\n",
    "    .format('orc') \\\n",
    "    .load('/home/jovyan/work/data/data_traffic')\n",
    "\n",
    "df_voice_traffic = spark \\\n",
    "    .read \\\n",
    "    .format('orc') \\\n",
    "    .load('/home/jovyan/work/data/voice_traffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce9be8-19d4-4bd5-946b-6cc709594191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client_profile = df_data_traffic \\\n",
    "    .select(\n",
    "        f.col('client_id'),\n",
    "        f.col('time_key'),\n",
    "        f.col('data_all_mb')\n",
    "    )\n",
    "\n",
    "df_client_profile = df_client_profile \\\n",
    "    .join(df_voice_traffic.select(\n",
    "                f.col('client_id'),\n",
    "                f.col('time_key'),\n",
    "                f.col('voice_out_sec'), \n",
    "                f.col('voice_in_sec')), \n",
    "          on=['client_id', 'time_key'], \n",
    "          how='left')\n",
    "\n",
    "df_client_profile = df_client_profile \\\n",
    "    .select(\n",
    "        f.col('client_id'),\n",
    "        f.slice(f.col('time_key').cast(str), 7).alias('time_key'),\n",
    "        f.col('voice_out_sec'), \n",
    "        f.col('voice_in_sec'),\n",
    "        f.col('data_all_mb')\n",
    "    ) \\\n",
    "    .groupby(to_group) \\\n",
    "    .agg(\n",
    "        f.sum(f.col('voice_out_sec')).alias('voice_out_sec'),\n",
    "        f.sum(f.col('voice_in_sec')).alias('voice_in_sec'),\n",
    "        f.sum(f.col('data_all_mb')).alias('data_all_mb')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997658d5-7404-4f7c-aaf3-c43025ae4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to aerospike DB\n",
    "\n",
    "df_client_profile.write \\\n",
    "    .mode('overwrite') \\\n",
    "    .format(\"aerospike\")  \\\n",
    "    .option(\"aerospike.writeset\", \"client_profile\")\\\n",
    "    .option(\"aerospike.updateByKey\", \"client_id\") \\\n",
    "    .save()"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cbe64-3fd6-4b64-b370-02a133259036",
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> ddaa9b1665c1e90358f140a30c8b99d8d5e526bc
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
