{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123398cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(bootstrap_servers=['kafka:9092'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils # не хочет\n",
    "import json\n",
    "\n",
    "sc = SparkContext(appName=\"PythonSparkStreamingKafka_RM_01\")\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, 60)\n",
    "kafkaStream = KafkaUtils.createStream(ssc, 'kafka:9092', 'spark-streaming', {'last_stream':1})\n",
    "parsed = kafkaStream.map(lambda v: json.loads(v[1]))\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424753f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция парсинга времени и рассчета дельты\n",
    "def time_delta(first_mes, second_mes):\n",
    "    p = re.compile(\"\\d{4}-\\d{2}-\\d{2}\\w{1}\\d{2}:\\d{2}:\\d{2}.\\d{3}\")\n",
    "    datetime1 = datetime.strptime(p.findall(first_mes[\"eventTime\"])[0], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    datetime2 = datetime.strptime(p.findall(second_mes[\"eventTime\"])[0], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    return(round((datetime2 - datetime1).total_seconds() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572828e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# алгоритм обработки потока по 1 сообщению и создания словаря с массивами сообщений по id клиента\n",
    "base_by_id = {}\n",
    "cnt = 0\n",
    "for message in consumer:\n",
    "    print(message)\n",
    "    if message[\"id\"] not in base_by_id:\n",
    "        base_by_id[message[\"id\"]] = [message]\n",
    "    elif message[\"id\"] in base_by_id:\n",
    "        base_by_id[message[\"id\"]].append(message)\n",
    "    cnt += 1\n",
    "    if cnt == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# алгоритм отбора событий по условиям задачи\n",
    "first_message = {}\n",
    "second_message = {}\n",
    "\n",
    "for key, value in base_by_id.items():\n",
    "    first_message = value[0]\n",
    "    counter = 0\n",
    "    for message in value:\n",
    "#         print(message)\n",
    "        if first_message[\"client\"] == \"mobile\":\n",
    "            first_message[\"chanel\"] = \"push\"\n",
    "            first_message.pop(\"client\")\n",
    "            base_by_id[key] = first_message\n",
    "            print(base_by_id[key])\n",
    "            break\n",
    "        elif first_message[\"client\"] == \"web\":\n",
    "            if len(value) > 1:\n",
    "                counter += 1\n",
    "                second_message = value[counter]\n",
    "                if (second_message[\"client\"] == \"mobile\") and (time_delta(first_message, second_message) <= 300000):\n",
    "                    second_message[\"chanel\"] = \"push\"\n",
    "                    second_message.pop(\"client\")\n",
    "                    base_by_id[key] = second_message\n",
    "                    print(base_by_id[key])\n",
    "                    break\n",
    "                else:\n",
    "                    second_message[\"chanel\"] = \"sms\"\n",
    "                    second_message.pop(\"client\")\n",
    "                    base_by_id[key] = second_message\n",
    "                    print(base_by_id[key])\n",
    "                    break\n",
    "            else:\n",
    "                first_message[\"chanel\"] = \"sms\"\n",
    "                first_message.pop(\"client\")\n",
    "                base_by_id[key] = first_message\n",
    "                print(base_by_id[key])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# достаем нужные значения из датасета\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Session')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "agg_usage = spark.read \\\n",
    "    .format('parquet') \\\n",
    "    .load(\"../data/agg_usage.parquet\")\n",
    "\n",
    "agg_usage.printSchema()\n",
    "agg_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "\n",
    "def serializer(message):\n",
    "    # message - JSON object\n",
    "    return json.dumps(message).encode('utf-8')\n",
    "\n",
    "\n",
    "def send_messages(producer, topic, path):\n",
    "    # producer - a Kafka Producer object\n",
    "    # topic - name of the Kafka Topic\n",
    "    # path - path to the JSON file\n",
    "\n",
    "    with open(path) as f:\n",
    "        for jsonObj in f:\n",
    "            message = json.loads(jsonObj)\n",
    "            producer.send(topic, message)\n",
    "\n",
    "    producer.flush()\n",
    "\n",
    "\n",
    "def on_send_success(record_metadata):\n",
    "    # record_metadata - Message sent to Kafka metadata\n",
    "    print(f\"Topic: {record_metadata.topic} / Partition: {record_metadata.partition} / Offset: {record_metadata.offset}\")\n",
    "\n",
    "\n",
    "# Create Producer\n",
    "producer = KafkaProducer(bootstrap_servers=['kafka:9092'],\n",
    "                         api_version=(0, 10), value_serializer=serializer)\n",
    "\n",
    "# Send messages to particular topic\n",
    "send_messages(producer, 'out_cm', base_by_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
